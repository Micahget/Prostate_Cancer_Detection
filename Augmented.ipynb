{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 100 non-null    int64  \n",
      " 1   diagnosis_result   100 non-null    object \n",
      " 2   radius             100 non-null    int64  \n",
      " 3   texture            100 non-null    int64  \n",
      " 4   perimeter          100 non-null    int64  \n",
      " 5   area               100 non-null    int64  \n",
      " 6   smoothness         100 non-null    float64\n",
      " 7   compactness        100 non-null    float64\n",
      " 8   symmetry           100 non-null    float64\n",
      " 9   fractal_dimension  100 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = './Prostate_Cancer.csv'\n",
    "data = pd.read_csv(dataset)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis_result</th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>fractal_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>151</td>\n",
       "      <td>954</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>386</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>135</td>\n",
       "      <td>1297</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis_result  radius  texture  perimeter  area  smoothness  compactness  \\\n",
       "0                M      23       12        151   954       0.143        0.278   \n",
       "1                B       9       13        133  1326       0.143        0.079   \n",
       "2                M      21       27        130  1203       0.125        0.160   \n",
       "3                M      14       16         78   386       0.070        0.284   \n",
       "4                M       9       19        135  1297       0.141        0.133   \n",
       "\n",
       "   symmetry  fractal_dimension  \n",
       "0     0.242              0.079  \n",
       "1     0.181              0.057  \n",
       "2     0.207              0.060  \n",
       "3     0.260              0.097  \n",
       "4     0.181              0.059  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop column 'id' from the dataset to avoid overfitting\n",
    "data.drop(columns=['id'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the features and diagnosis result\n",
    "\n",
    "\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noisy_data = data.copy()\n",
    "    for column in noisy_data.columns:\n",
    "        if column != 'diagnosis_result':\n",
    "            noise = np.random.normal(\n",
    "                0, noise_level, size=noisy_data[column].shape)\n",
    "            noisy_data[column] += noise\n",
    "    return noisy_data\n",
    "\n",
    "\n",
    "noisy_data = add_noise(data)\n",
    "augmented_data = pd.concat([data, noisy_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data, scale_factor_range=(0.9, 1.1)):\n",
    "    scaled_data = data.copy()\n",
    "    for column in scaled_data.columns:\n",
    "        if column != 'diagnosis_result':\n",
    "            scale_factor = np.random.uniform(\n",
    "                scale_factor_range[0], scale_factor_range[1])\n",
    "            scaled_data[column] *= scale_factor\n",
    "    return scaled_data\n",
    "\n",
    "\n",
    "scaled_data = scale_data(data)\n",
    "augmented_data = pd.concat([augmented_data, scaled_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "features = data.drop('diagnosis_result', axis=1)\n",
    "labels = data['diagnosis_result']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(features, labels)\n",
    "\n",
    "smote_data = pd.DataFrame(X_resampled, columns=features.columns)\n",
    "smote_data['diagnosis_result'] = y_resampled\n",
    "augmented_data = pd.concat([augmented_data, smote_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_data(data):\n",
    "    permuted_data = data.copy()\n",
    "    for column in permuted_data.columns:\n",
    "        if column != 'diagnosis_result':\n",
    "            permuted_data[column] = np.random.permutation(\n",
    "                permuted_data[column].values)\n",
    "    return permuted_data\n",
    "\n",
    "\n",
    "permuted_data = permute_data(data)\n",
    "augmented_data = pd.concat([augmented_data, permuted_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_data(data, n_samples=None):\n",
    "    if n_samples is None:\n",
    "        n_samples = len(data)\n",
    "    bootstrap_sample = data.sample(n=n_samples, replace=True)\n",
    "    return bootstrap_sample\n",
    "\n",
    "\n",
    "bootstrap_data = bootstrap_data(data)\n",
    "augmented_data = pd.concat([augmented_data, bootstrap_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the augmented data\n",
    "X = augmented_data.drop('diagnosis_result', axis=1)\n",
    "y = augmented_data['diagnosis_result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier (as an example)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Fine-tuned Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=10,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2\n",
    ")\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Decision Tree Accuracy: {dt_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "# lr_model = LogisticRegression(max_iter=1000)\n",
    "# lr_model.fit(X_train, y_train)\n",
    "\n",
    "#fine tuning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fine-tuned Logistic Regression\n",
    "lr_model = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    solver='liblinear',\n",
    "    max_iter=200\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.784\n"
     ]
    }
   ],
   "source": [
    "# # Train a Naive Bayes model\n",
    "# nb_model = GaussianNB()\n",
    "# nb_model.fit(X_train, y_train)\n",
    "# fine tuning\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Fine-tuned Naive Bayes\n",
    "nb_model = GaussianNB(var_smoothing=1e-9)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Naive Bayes Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.888\n",
      "Logistic Regression Accuracy: 0.792\n",
      "Naive Bayes Accuracy: 0.784\n"
     ]
    }
   ],
   "source": [
    "print(f'Decision Tree Accuracy: {dt_accuracy}')\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
    "print(f'Naive Bayes Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters for Decision Tree: {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Tuned Decision Tree Accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_dt = GridSearchCV(\n",
    "    estimator=dt_model, param_grid=param_grid_dt, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "print(f'Best parameters for Decision Tree: {best_params_dt}')\n",
    "\n",
    "# Train with the best parameters\n",
    "dt_model_tuned = DecisionTreeClassifier(**best_params_dt)\n",
    "dt_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = dt_model_tuned.predict(X_test)\n",
    "dt_accuracy_tuned = accuracy_score(y_test, y_pred)\n",
    "print(f'Tuned Decision Tree Accuracy: {dt_accuracy_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best parameters for Logistic Regression: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Logistic Regression Best Accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_lr = GridSearchCV(\n",
    "    estimator=lr_model, param_grid=param_grid_lr, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "print(f'Best parameters for Logistic Regression: {best_params_lr}')\n",
    "\n",
    "# Train with the best parameters\n",
    "lr_model_tuned = LogisticRegression(**best_params_lr)\n",
    "lr_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lr = lr_model_tuned.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'Logistic Regression Best Accuracy: {lr_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best parameters for Naive Bayes: {'var_smoothing': 1e-07}\n",
      "Naive Bayes Best Accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the parameter grid for Naive Bayes\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': [1e-11, 1e-10, 1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_nb = GridSearchCV(\n",
    "    estimator=nb_model, param_grid=param_grid_nb, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_nb = grid_search_nb.best_params_\n",
    "print(f'Best parameters for Naive Bayes: {best_params_nb}')\n",
    "\n",
    "# Train with the best parameters\n",
    "nb_model_tuned = GaussianNB(**best_params_nb)\n",
    "nb_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_nb = nb_model_tuned.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f'Naive Bayes Best Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Accuracy: 0.896\n",
      "Logistic Regression Best Accuracy: 0.808\n",
      "Naive Bayes Best Accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "print(f'Decision Tree Best Accuracy: {dt_accuracy}')\n",
    "print(f'Logistic Regression Best Accuracy: {lr_accuracy}')\n",
    "print(f'Naive Bayes Best Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Pipeline Accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Example of a more advanced pipeline with feature engineering and ensemble methods\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    # Add polynomial features\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('pca', PCA(n_components=10)),  # Dimensionality reduction\n",
    "    ('feature_selection', SelectFromModel(\n",
    "        RandomForestClassifier(n_estimators=100))),  # Feature selection\n",
    "    ('ensemble', StackingClassifier(  # Ensemble method\n",
    "        estimators=[\n",
    "            ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "            ('gb', GradientBoostingClassifier(n_estimators=100)),\n",
    "            ('lr', LogisticRegression())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression()\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Ensemble Pipeline Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:33:25,592] A new study created in memory with name: no-name-b27ee6fe-c711-4cea-a719-aff9173fd9f5\n",
      "[I 2024-06-22 12:33:25,616] Trial 0 finished with value: 0.8497171717171718 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8497171717171718.\n",
      "[I 2024-06-22 12:33:25,642] Trial 1 finished with value: 0.8595959595959595 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,664] Trial 2 finished with value: 0.8495757575757577 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,690] Trial 3 finished with value: 0.8516767676767676 and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,715] Trial 4 finished with value: 0.8375555555555556 and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,737] Trial 5 finished with value: 0.8295353535353535 and parameters: {'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 14}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,753] Trial 6 finished with value: 0.8275959595959594 and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 11}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,780] Trial 7 finished with value: 0.8375959595959597 and parameters: {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,803] Trial 8 finished with value: 0.8315353535353536 and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 16, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,818] Trial 9 finished with value: 0.8114949494949496 and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,861] Trial 10 finished with value: 0.8537373737373738 and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,894] Trial 11 finished with value: 0.8395959595959596 and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.8595959595959595.\n",
      "[I 2024-06-22 12:33:25,926] Trial 12 finished with value: 0.8737979797979799 and parameters: {'criterion': 'gini', 'max_depth': 31, 'min_samples_split': 11, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8737979797979799.\n",
      "[I 2024-06-22 12:33:25,958] Trial 13 finished with value: 0.8595757575757575 and parameters: {'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8737979797979799.\n",
      "[I 2024-06-22 12:33:25,989] Trial 14 finished with value: 0.8355555555555556 and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 12 with value: 0.8737979797979799.\n",
      "[I 2024-06-22 12:33:26,014] Trial 15 finished with value: 0.8355151515151515 and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8737979797979799.\n",
      "[I 2024-06-22 12:33:26,054] Trial 16 finished with value: 0.8837979797979798 and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,083] Trial 17 finished with value: 0.8195555555555556 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 16}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,114] Trial 18 finished with value: 0.8516363636363635 and parameters: {'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,150] Trial 19 finished with value: 0.8395757575757576 and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 9}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,181] Trial 20 finished with value: 0.8475151515151514 and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,211] Trial 21 finished with value: 0.8616161616161616 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 15, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,248] Trial 22 finished with value: 0.8375555555555556 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,282] Trial 23 finished with value: 0.8537373737373738 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,321] Trial 24 finished with value: 0.8657373737373737 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,361] Trial 25 finished with value: 0.8355151515151515 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,396] Trial 26 finished with value: 0.8175959595959595 and parameters: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,429] Trial 27 finished with value: 0.8637575757575757 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,463] Trial 28 finished with value: 0.8256565656565658 and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,498] Trial 29 finished with value: 0.8516767676767676 and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,532] Trial 30 finished with value: 0.8556969696969696 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,564] Trial 31 finished with value: 0.8617575757575757 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,597] Trial 32 finished with value: 0.8657171717171718 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,631] Trial 33 finished with value: 0.8596969696969696 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,665] Trial 34 finished with value: 0.8637171717171718 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,698] Trial 35 finished with value: 0.8576767676767677 and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,734] Trial 36 finished with value: 0.8517171717171717 and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,763] Trial 37 finished with value: 0.8274949494949496 and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,803] Trial 38 finished with value: 0.8516969696969697 and parameters: {'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,836] Trial 39 finished with value: 0.8335555555555556 and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,861] Trial 40 finished with value: 0.8637171717171718 and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,905] Trial 41 finished with value: 0.8697979797979798 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,930] Trial 42 finished with value: 0.8537373737373738 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:26,974] Trial 43 finished with value: 0.8716969696969696 and parameters: {'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.8837979797979798.\n",
      "[I 2024-06-22 12:33:27,007] Trial 44 finished with value: 0.8838181818181818 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 44 with value: 0.8838181818181818.\n",
      "[I 2024-06-22 12:33:27,045] Trial 45 finished with value: 0.8275555555555556 and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 10}. Best is trial 44 with value: 0.8838181818181818.\n",
      "[I 2024-06-22 12:33:27,078] Trial 46 finished with value: 0.8135353535353534 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 12}. Best is trial 44 with value: 0.8838181818181818.\n",
      "[I 2024-06-22 12:33:27,113] Trial 47 finished with value: 0.8858181818181817 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 47 with value: 0.8858181818181817.\n",
      "[I 2024-06-22 12:33:27,147] Trial 48 finished with value: 0.8858181818181817 and parameters: {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 47 with value: 0.8858181818181817.\n",
      "[I 2024-06-22 12:33:27,184] Trial 49 finished with value: 0.8636767676767677 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 47 with value: 0.8858181818181817.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Accuracy: 0.912\n",
      "Best parameters for Decision Tree: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 3}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the objective function for Decision Tree\n",
    "\n",
    "\n",
    "def objective_dt(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 16)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 16)\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(dt_model, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create the study and optimize\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective_dt, n_trials=50)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params_dt = study_dt.best_params\n",
    "dt_model_tuned = DecisionTreeClassifier(**best_params_dt)\n",
    "dt_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dt = dt_model_tuned.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f'Decision Tree Best Accuracy: {dt_accuracy}')\n",
    "print(f'Best parameters for Decision Tree: {best_params_dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:35:09,569] A new study created in memory with name: no-name-75524e48-db6a-41f8-bc21-f843e2d920e9\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,591] Trial 0 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 7.896696651106577e-09}. Best is trial 0 with value: 0.7734343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,622] Trial 1 finished with value: 0.7553737373737374 and parameters: {'var_smoothing': 1.6966468982792169e-10}. Best is trial 0 with value: 0.7734343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,646] Trial 2 finished with value: 0.7593939393939394 and parameters: {'var_smoothing': 5.4818045366903406e-11}. Best is trial 0 with value: 0.7734343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,661] Trial 3 finished with value: 0.7573737373737374 and parameters: {'var_smoothing': 9.77408241746213e-11}. Best is trial 0 with value: 0.7734343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,685] Trial 4 finished with value: 0.7754343434343434 and parameters: {'var_smoothing': 8.30122578586276e-09}. Best is trial 4 with value: 0.7754343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,702] Trial 5 finished with value: 0.7533737373737374 and parameters: {'var_smoothing': 2.3661545776934757e-10}. Best is trial 4 with value: 0.7754343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,711] Trial 6 finished with value: 0.7873939393939395 and parameters: {'var_smoothing': 5.66934062172105e-08}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,727] Trial 7 finished with value: 0.7573939393939394 and parameters: {'var_smoothing': 2.568947848330787e-11}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,755] Trial 8 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 5.027284187470937e-09}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,774] Trial 9 finished with value: 0.7573939393939394 and parameters: {'var_smoothing': 2.3416732547704988e-11}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,797] Trial 10 finished with value: 0.7813939393939394 and parameters: {'var_smoothing': 8.958598442220647e-08}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,814] Trial 11 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 9.849312329316585e-08}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,839] Trial 12 finished with value: 0.7873939393939395 and parameters: {'var_smoothing': 5.974641952058753e-08}. Best is trial 6 with value: 0.7873939393939395.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,860] Trial 13 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.059660294620417e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,878] Trial 14 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 2.1885001329130375e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,897] Trial 15 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 1.479941494318601e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,924] Trial 16 finished with value: 0.7914545454545454 and parameters: {'var_smoothing': 1.8532894038060443e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,946] Trial 17 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 1.3144318349689952e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,961] Trial 18 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 2.5808541103844055e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:09,990] Trial 19 finished with value: 0.7573737373737373 and parameters: {'var_smoothing': 4.450741949586063e-10}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,011] Trial 20 finished with value: 0.7694141414141414 and parameters: {'var_smoothing': 4.366520578533002e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,027] Trial 21 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 2.6134626901126872e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,054] Trial 22 finished with value: 0.7994545454545456 and parameters: {'var_smoothing': 1.9964527841171263e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,077] Trial 23 finished with value: 0.7914545454545454 and parameters: {'var_smoothing': 1.3821445077042831e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,097] Trial 24 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 2.7720262779736953e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,118] Trial 25 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.60711281761415e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,138] Trial 26 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.708138664564545e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,159] Trial 27 finished with value: 0.7913939393939394 and parameters: {'var_smoothing': 4.8441224124740936e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,176] Trial 28 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.612458112457049e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,198] Trial 29 finished with value: 0.7794343434343435 and parameters: {'var_smoothing': 1.0470202980607712e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,213] Trial 30 finished with value: 0.7573737373737373 and parameters: {'var_smoothing': 5.881302292758396e-10}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,242] Trial 31 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.764065030501606e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,268] Trial 32 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 4.784549420603427e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,289] Trial 33 finished with value: 0.7854545454545455 and parameters: {'var_smoothing': 1.1143117709690198e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,310] Trial 34 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.819780540172495e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,331] Trial 35 finished with value: 0.7573939393939394 and parameters: {'var_smoothing': 1.0558146539556371e-11}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,352] Trial 36 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 6.956675656004109e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,362] Trial 37 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 2.7454646959131967e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,394] Trial 38 finished with value: 0.7853939393939395 and parameters: {'var_smoothing': 6.613280822758999e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,416] Trial 39 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.27395392716449e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,429] Trial 40 finished with value: 0.7914545454545454 and parameters: {'var_smoothing': 1.4679196088902313e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,445] Trial 41 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 3.459532090644525e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,479] Trial 42 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 7.634161018984192e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,495] Trial 43 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.313571855485156e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,512] Trial 44 finished with value: 0.7893939393939394 and parameters: {'var_smoothing': 5.2600258149824846e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,528] Trial 45 finished with value: 0.7573737373737374 and parameters: {'var_smoothing': 9.326638025415989e-11}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,561] Trial 46 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 8.166771109221265e-09}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,579] Trial 47 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 9.890249882464689e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,596] Trial 48 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 2.640362845343815e-08}. Best is trial 13 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2932803339.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:35:10,634] Trial 49 finished with value: 0.7894545454545454 and parameters: {'var_smoothing': 1.3167999942510904e-08}. Best is trial 13 with value: 0.8034343434343434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Best Accuracy: 0.824\n",
      "Best parameters for Naive Bayes: {'var_smoothing': 3.059660294620417e-08}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the objective function for Naive Bayes\n",
    "\n",
    "\n",
    "def objective_nb(trial):\n",
    "    var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
    "\n",
    "    nb_model = GaussianNB(var_smoothing=var_smoothing)\n",
    "\n",
    "    score = cross_val_score(nb_model, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create the study and optimize\n",
    "study_nb = optuna.create_study(direction='maximize')\n",
    "study_nb.optimize(objective_nb, n_trials=50)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params_nb = study_nb.best_params\n",
    "nb_model_tuned = GaussianNB(**best_params_nb)\n",
    "nb_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_nb = nb_model_tuned.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f'Naive Bayes Best Accuracy: {nb_accuracy}')\n",
    "print(f'Best parameters for Naive Bayes: {best_params_nb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:37:10,635] A new study created in memory with name: no-name-10fd6368-fcac-472f-a703-4c295dc2868c\n",
      "[I 2024-06-22 12:37:10,660] Trial 0 finished with value: 0.8275555555555556 and parameters: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 12, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.8275555555555556.\n",
      "[I 2024-06-22 12:37:10,683] Trial 1 finished with value: 0.8355353535353535 and parameters: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 13}. Best is trial 1 with value: 0.8355353535353535.\n",
      "[I 2024-06-22 12:37:10,718] Trial 2 finished with value: 0.8355555555555556 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 14, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.8355555555555556.\n",
      "[I 2024-06-22 12:37:10,741] Trial 3 finished with value: 0.8175151515151515 and parameters: {'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 15}. Best is trial 2 with value: 0.8355555555555556.\n",
      "[I 2024-06-22 12:37:10,750] Trial 4 finished with value: 0.8516767676767676 and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,785] Trial 5 finished with value: 0.8295959595959594 and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 14}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,806] Trial 6 finished with value: 0.8316161616161617 and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,817] Trial 7 finished with value: 0.8195555555555556 and parameters: {'criterion': 'gini', 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 16}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,849] Trial 8 finished with value: 0.8095151515151515 and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,872] Trial 9 finished with value: 0.8375959595959597 and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 4 with value: 0.8516767676767676.\n",
      "[I 2024-06-22 12:37:10,900] Trial 10 finished with value: 0.8716767676767677 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8716767676767677.\n",
      "[I 2024-06-22 12:37:10,936] Trial 11 finished with value: 0.8657171717171718 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.8716767676767677.\n",
      "[I 2024-06-22 12:37:10,967] Trial 12 finished with value: 0.8717979797979798 and parameters: {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,000] Trial 13 finished with value: 0.8577777777777778 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,032] Trial 14 finished with value: 0.8475353535353536 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,064] Trial 15 finished with value: 0.8696767676767676 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,086] Trial 16 finished with value: 0.8355151515151515 and parameters: {'criterion': 'gini', 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,128] Trial 17 finished with value: 0.8195555555555556 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 11}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,157] Trial 18 finished with value: 0.8617171717171717 and parameters: {'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,194] Trial 19 finished with value: 0.8637373737373737 and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,228] Trial 20 finished with value: 0.8336767676767677 and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,263] Trial 21 finished with value: 0.8676767676767676 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,297] Trial 22 finished with value: 0.8716767676767677 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,324] Trial 23 finished with value: 0.8717373737373737 and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,365] Trial 24 finished with value: 0.8696767676767678 and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,385] Trial 25 finished with value: 0.8597373737373738 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,431] Trial 26 finished with value: 0.8295353535353535 and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,451] Trial 27 finished with value: 0.8677373737373737 and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,498] Trial 28 finished with value: 0.8617575757575757 and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,531] Trial 29 finished with value: 0.8135353535353534 and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 12}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,564] Trial 30 finished with value: 0.8114949494949496 and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 11, 'min_samples_leaf': 10}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,597] Trial 31 finished with value: 0.8696565656565657 and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,630] Trial 32 finished with value: 0.8716969696969696 and parameters: {'criterion': 'gini', 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.8717979797979798.\n",
      "[I 2024-06-22 12:37:11,650] Trial 33 finished with value: 0.8737777777777778 and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 33 with value: 0.8737777777777778.\n",
      "[I 2024-06-22 12:37:11,699] Trial 34 finished with value: 0.8757575757575757 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,734] Trial 35 finished with value: 0.8757575757575757 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,768] Trial 36 finished with value: 0.8476565656565656 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,806] Trial 37 finished with value: 0.8617171717171717 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,837] Trial 38 finished with value: 0.8616969696969697 and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,868] Trial 39 finished with value: 0.8215757575757575 and parameters: {'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,901] Trial 40 finished with value: 0.8396363636363636 and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 13, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.8757575757575757.\n",
      "[I 2024-06-22 12:37:11,954] Trial 41 finished with value: 0.8877777777777778 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:11,994] Trial 42 finished with value: 0.8616565656565657 and parameters: {'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,032] Trial 43 finished with value: 0.8757373737373737 and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,067] Trial 44 finished with value: 0.8356363636363635 and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,103] Trial 45 finished with value: 0.8717979797979798 and parameters: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,135] Trial 46 finished with value: 0.8656969696969696 and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,176] Trial 47 finished with value: 0.8577171717171715 and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,212] Trial 48 finished with value: 0.8637171717171718 and parameters: {'criterion': 'entropy', 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 41 with value: 0.8877777777777778.\n",
      "[I 2024-06-22 12:37:12,234] Trial 49 finished with value: 0.8334949494949495 and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 16, 'min_samples_leaf': 6}. Best is trial 41 with value: 0.8877777777777778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1}\n",
      "Decision Tree Best Accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the objective function for Decision Tree\n",
    "\n",
    "\n",
    "def objective_dt(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 16)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 16)\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(dt_model, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create the study and optimize\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective_dt, n_trials=50)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params_dt = study_dt.best_params\n",
    "print(f'Best parameters for Decision Tree: {best_params_dt}')\n",
    "\n",
    "dt_model_tuned = DecisionTreeClassifier(**best_params_dt)\n",
    "dt_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dt = dt_model_tuned.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f'Decision Tree Best Accuracy: {dt_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:37:38,306] A new study created in memory with name: no-name-c1cacf83-cdc7-4ffd-bf80-e91779a8393a\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,339] Trial 0 finished with value: 0.6012121212121212 and parameters: {'penalty': 'l1', 'C': 0.001267317053641059, 'solver': 'liblinear', 'max_iter': 164}. Best is trial 0 with value: 0.6012121212121212.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,341] Trial 1 pruned. \n",
      "[I 2024-06-22 12:37:38,405] Trial 2 finished with value: 0.8095151515151515 and parameters: {'penalty': 'l2', 'C': 0.5687336025161197, 'solver': 'lbfgs', 'max_iter': 246}. Best is trial 2 with value: 0.8095151515151515.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,406] Trial 3 pruned. \n",
      "[I 2024-06-22 12:37:38,453] Trial 4 finished with value: 0.7955151515151515 and parameters: {'penalty': 'l2', 'C': 0.0006605068947361623, 'solver': 'lbfgs', 'max_iter': 168}. Best is trial 2 with value: 0.8095151515151515.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,453] Trial 5 pruned. \n",
      "[I 2024-06-22 12:37:38,453] Trial 6 pruned. \n",
      "[I 2024-06-22 12:37:38,453] Trial 7 pruned. \n",
      "[I 2024-06-22 12:37:38,482] Trial 8 finished with value: 0.6012121212121212 and parameters: {'penalty': 'l1', 'C': 0.0008201648088314767, 'solver': 'liblinear', 'max_iter': 279}. Best is trial 2 with value: 0.8095151515151515.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,505] Trial 9 finished with value: 0.8295555555555556 and parameters: {'penalty': 'l1', 'C': 1.272452502962654, 'solver': 'liblinear', 'max_iter': 260}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 12:37:38,606] Trial 10 finished with value: 0.7274343434343434 and parameters: {'penalty': 'l1', 'C': 21.645181124644186, 'solver': 'saga', 'max_iter': 299}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 12:37:38,679] Trial 11 finished with value: 0.7314343434343433 and parameters: {'penalty': 'l2', 'C': 0.6663049945924173, 'solver': 'saga', 'max_iter': 234}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,688] Trial 12 pruned. \n",
      "[I 2024-06-22 12:37:38,754] Trial 13 finished with value: 0.8075151515151516 and parameters: {'penalty': 'l2', 'C': 0.06235619597942772, 'solver': 'lbfgs', 'max_iter': 259}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 12:37:38,830] Trial 14 finished with value: 0.7273939393939394 and parameters: {'penalty': 'l1', 'C': 6.148994295366513, 'solver': 'saga', 'max_iter': 207}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:38,839] Trial 15 pruned. \n",
      "[I 2024-06-22 12:37:38,839] Trial 16 pruned. \n",
      "[I 2024-06-22 12:37:38,854] Trial 17 pruned. \n",
      "[I 2024-06-22 12:37:38,854] Trial 18 pruned. \n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 12:37:38,938] Trial 19 finished with value: 0.7334343434343434 and parameters: {'penalty': 'l2', 'C': 0.01459002779914609, 'solver': 'saga', 'max_iter': 273}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,016] Trial 20 finished with value: 0.8215353535353535 and parameters: {'penalty': 'l2', 'C': 3.8832239673648643, 'solver': 'lbfgs', 'max_iter': 298}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,092] Trial 21 finished with value: 0.8195353535353535 and parameters: {'penalty': 'l2', 'C': 4.444212507540105, 'solver': 'lbfgs', 'max_iter': 298}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,160] Trial 22 finished with value: 0.8215353535353535 and parameters: {'penalty': 'l2', 'C': 4.130928776444587, 'solver': 'lbfgs', 'max_iter': 295}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,239] Trial 23 finished with value: 0.8175555555555556 and parameters: {'penalty': 'l2', 'C': 33.921007245529665, 'solver': 'lbfgs', 'max_iter': 269}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,313] Trial 24 finished with value: 0.8255353535353536 and parameters: {'penalty': 'l2', 'C': 16.675104162799794, 'solver': 'lbfgs', 'max_iter': 287}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,323] Trial 25 pruned. \n",
      "[I 2024-06-22 12:37:39,334] Trial 26 pruned. \n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-06-22 12:37:39,405] Trial 27 finished with value: 0.8195353535353535 and parameters: {'penalty': 'l2', 'C': 11.63570916065351, 'solver': 'lbfgs', 'max_iter': 103}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 12:37:39,485] Trial 28 finished with value: 0.7314343434343433 and parameters: {'penalty': 'l1', 'C': 1.5287746523666619, 'solver': 'saga', 'max_iter': 225}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,520] Trial 29 finished with value: 0.7734949494949495 and parameters: {'penalty': 'l1', 'C': 0.30296146908801386, 'solver': 'liblinear', 'max_iter': 286}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,520] Trial 30 pruned. \n",
      "[I 2024-06-22 12:37:39,607] Trial 31 finished with value: 0.8235353535353536 and parameters: {'penalty': 'l2', 'C': 3.26706831855767, 'solver': 'lbfgs', 'max_iter': 299}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,676] Trial 32 finished with value: 0.8175151515151515 and parameters: {'penalty': 'l2', 'C': 2.596344942062056, 'solver': 'lbfgs', 'max_iter': 300}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,754] Trial 33 finished with value: 0.8295353535353535 and parameters: {'penalty': 'l2', 'C': 15.181885002865284, 'solver': 'lbfgs', 'max_iter': 281}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,820] Trial 34 finished with value: 0.8235353535353533 and parameters: {'penalty': 'l2', 'C': 11.658827057731111, 'solver': 'lbfgs', 'max_iter': 246}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,893] Trial 35 finished with value: 0.8175555555555556 and parameters: {'penalty': 'l2', 'C': 33.70085325244144, 'solver': 'lbfgs', 'max_iter': 284}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,974] Trial 36 finished with value: 0.8055151515151515 and parameters: {'penalty': 'l2', 'C': 0.4708548604383203, 'solver': 'lbfgs', 'max_iter': 186}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:39,984] Trial 37 pruned. \n",
      "[I 2024-06-22 12:37:40,057] Trial 38 finished with value: 0.8155555555555555 and parameters: {'penalty': 'l2', 'C': 98.79232661761363, 'solver': 'lbfgs', 'max_iter': 251}. Best is trial 9 with value: 0.8295555555555556.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,088] Trial 39 finished with value: 0.8315555555555555 and parameters: {'penalty': 'l1', 'C': 0.9374500448076619, 'solver': 'liblinear', 'max_iter': 260}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,129] Trial 40 finished with value: 0.8235555555555555 and parameters: {'penalty': 'l1', 'C': 0.8166429630145025, 'solver': 'liblinear', 'max_iter': 156}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,154] Trial 41 finished with value: 0.8295555555555556 and parameters: {'penalty': 'l1', 'C': 1.1251345389139473, 'solver': 'liblinear', 'max_iter': 143}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,202] Trial 42 finished with value: 0.8275353535353535 and parameters: {'penalty': 'l1', 'C': 1.3591273750359958, 'solver': 'liblinear', 'max_iter': 140}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,237] Trial 43 finished with value: 0.7734949494949495 and parameters: {'penalty': 'l1', 'C': 0.3363929679480767, 'solver': 'liblinear', 'max_iter': 152}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,270] Trial 44 finished with value: 0.8295555555555556 and parameters: {'penalty': 'l1', 'C': 1.3568705600097763, 'solver': 'liblinear', 'max_iter': 140}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,311] Trial 45 finished with value: 0.8275555555555556 and parameters: {'penalty': 'l1', 'C': 0.8760496084030458, 'solver': 'liblinear', 'max_iter': 105}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,340] Trial 46 finished with value: 0.6012121212121212 and parameters: {'penalty': 'l1', 'C': 0.00011801582143056235, 'solver': 'liblinear', 'max_iter': 118}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,371] Trial 47 finished with value: 0.7574343434343435 and parameters: {'penalty': 'l1', 'C': 0.07234196636664851, 'solver': 'liblinear', 'max_iter': 168}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,404] Trial 48 finished with value: 0.7714545454545455 and parameters: {'penalty': 'l1', 'C': 0.13663339084871964, 'solver': 'liblinear', 'max_iter': 141}. Best is trial 39 with value: 0.8315555555555555.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\2265826135.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
      "[I 2024-06-22 12:37:40,434] Trial 49 finished with value: 0.6793939393939394 and parameters: {'penalty': 'l1', 'C': 0.0030398606999746925, 'solver': 'liblinear', 'max_iter': 195}. Best is trial 39 with value: 0.8315555555555555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'penalty': 'l1', 'C': 0.9374500448076619, 'solver': 'liblinear', 'max_iter': 260}\n",
      "Logistic Regression Best Accuracy: 0.808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the objective function for Logistic Regression\n",
    "\n",
    "\n",
    "def objective_lr(trial):\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
    "    solver = trial.suggest_categorical(\n",
    "        'solver', ['liblinear', 'lbfgs', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "\n",
    "    # Ensure solver compatibility with penalty\n",
    "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    if penalty == 'l2' and solver == 'liblinear':\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    lr_model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(lr_model, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create the study and optimize\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_lr.optimize(objective_lr, n_trials=50)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params_lr = study_lr.best_params\n",
    "print(f'Best parameters for Logistic Regression: {best_params_lr}')\n",
    "\n",
    "lr_model_tuned = LogisticRegression(**best_params_lr)\n",
    "lr_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lr = lr_model_tuned.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f'Logistic Regression Best Accuracy: {lr_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:38:02,000] A new study created in memory with name: no-name-28329521-285d-4680-9462-2930af4dc21f\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,020] Trial 0 finished with value: 0.7994141414141415 and parameters: {'var_smoothing': 4.6205758423348436e-08}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,029] Trial 1 finished with value: 0.7593939393939394 and parameters: {'var_smoothing': 7.601218288453327e-11}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,055] Trial 2 finished with value: 0.7553737373737374 and parameters: {'var_smoothing': 1.348894712760798e-10}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,061] Trial 3 finished with value: 0.7914545454545454 and parameters: {'var_smoothing': 1.4830072342267498e-08}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,090] Trial 4 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 7.0855583761478595e-09}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,107] Trial 5 finished with value: 0.7533737373737374 and parameters: {'var_smoothing': 2.1675669242161043e-10}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,124] Trial 6 finished with value: 0.7754343434343434 and parameters: {'var_smoothing': 8.531795775135094e-09}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,141] Trial 7 finished with value: 0.7774343434343434 and parameters: {'var_smoothing': 9.590935532310494e-09}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,159] Trial 8 finished with value: 0.7553737373737374 and parameters: {'var_smoothing': 1.3701912339885212e-10}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,177] Trial 9 finished with value: 0.7553737373737374 and parameters: {'var_smoothing': 1.1659172335118718e-10}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,199] Trial 10 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 7.619514521829067e-08}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,220] Trial 11 finished with value: 0.7813939393939394 and parameters: {'var_smoothing': 8.938833837413091e-08}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,242] Trial 12 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 1.4907432574917955e-09}. Best is trial 0 with value: 0.7994141414141415.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,264] Trial 13 finished with value: 0.7994343434343435 and parameters: {'var_smoothing': 2.5505495746595636e-08}. Best is trial 13 with value: 0.7994343434343435.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,286] Trial 14 finished with value: 0.7674141414141414 and parameters: {'var_smoothing': 1.7881984181845186e-09}. Best is trial 13 with value: 0.7994343434343435.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,307] Trial 15 finished with value: 0.7573939393939394 and parameters: {'var_smoothing': 1.3685622905408243e-11}. Best is trial 13 with value: 0.7994343434343435.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,326] Trial 16 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.172217878276516e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,342] Trial 17 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 2.3918225173669007e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,359] Trial 18 finished with value: 0.7694141414141414 and parameters: {'var_smoothing': 3.5851230825889275e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,391] Trial 19 finished with value: 0.7593737373737373 and parameters: {'var_smoothing': 7.636700714980396e-10}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,413] Trial 20 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.200456238467591e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,434] Trial 21 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 2.8842411394994753e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,456] Trial 22 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 2.464313480507294e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,475] Trial 23 finished with value: 0.7694141414141414 and parameters: {'var_smoothing': 3.5630236264159122e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,492] Trial 24 finished with value: 0.7994141414141415 and parameters: {'var_smoothing': 4.5654756403987635e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,509] Trial 25 finished with value: 0.7573737373737373 and parameters: {'var_smoothing': 4.90313565177649e-10}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,542] Trial 26 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 5.817642414811425e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,562] Trial 27 finished with value: 0.7914545454545454 and parameters: {'var_smoothing': 1.4820172369864584e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,576] Trial 28 finished with value: 0.7913939393939394 and parameters: {'var_smoothing': 5.072631759668629e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,590] Trial 29 finished with value: 0.7994141414141415 and parameters: {'var_smoothing': 4.28784818195106e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,626] Trial 30 finished with value: 0.7694141414141413 and parameters: {'var_smoothing': 2.5208177971970465e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,644] Trial 31 finished with value: 0.7994545454545456 and parameters: {'var_smoothing': 1.9999105184342695e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,670] Trial 32 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 2.5230868519724352e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,693] Trial 33 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 9.4844153373676e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,716] Trial 34 finished with value: 0.7894545454545454 and parameters: {'var_smoothing': 1.3303060906340356e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,736] Trial 35 finished with value: 0.7994141414141415 and parameters: {'var_smoothing': 4.212507153023363e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,757] Trial 36 finished with value: 0.7734343434343434 and parameters: {'var_smoothing': 5.006018793697636e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,779] Trial 37 finished with value: 0.7573939393939394 and parameters: {'var_smoothing': 2.944253884465186e-11}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,792] Trial 38 finished with value: 0.7854545454545455 and parameters: {'var_smoothing': 1.0789938347007208e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,809] Trial 39 finished with value: 0.7934545454545454 and parameters: {'var_smoothing': 1.7649952674953364e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,841] Trial 40 finished with value: 0.7873939393939395 and parameters: {'var_smoothing': 5.806509292964772e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,863] Trial 41 finished with value: 0.8014343434343434 and parameters: {'var_smoothing': 3.5936753195025065e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,884] Trial 42 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 2.3522127686133372e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,892] Trial 43 finished with value: 0.7754343434343434 and parameters: {'var_smoothing': 8.61334574345539e-09}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,927] Trial 44 finished with value: 0.7974343434343435 and parameters: {'var_smoothing': 2.1659376461280005e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,949] Trial 45 finished with value: 0.7833939393939394 and parameters: {'var_smoothing': 7.381434258550361e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,966] Trial 46 finished with value: 0.7894545454545454 and parameters: {'var_smoothing': 1.3085542405788332e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:02,993] Trial 47 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.2811715431805625e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:03,015] Trial 48 finished with value: 0.7873939393939395 and parameters: {'var_smoothing': 6.293128865299829e-08}. Best is trial 16 with value: 0.8034343434343434.\n",
      "C:\\Users\\mikiy\\AppData\\Local\\Temp\\ipykernel_38760\\566318546.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
      "[I 2024-06-22 12:38:03,036] Trial 49 finished with value: 0.8034343434343434 and parameters: {'var_smoothing': 3.3143247007123974e-08}. Best is trial 16 with value: 0.8034343434343434.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Naive Bayes: {'var_smoothing': 3.172217878276516e-08}\n",
      "Naive Bayes Best Accuracy: 0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the objective function for Naive Bayes\n",
    "\n",
    "\n",
    "def objective_nb(trial):\n",
    "    var_smoothing = trial.suggest_loguniform('var_smoothing', 1e-11, 1e-7)\n",
    "\n",
    "    nb_model = GaussianNB(var_smoothing=var_smoothing)\n",
    "\n",
    "    score = cross_val_score(nb_model, X_train, y_train,\n",
    "                            cv=5, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create the study and optimize\n",
    "study_nb = optuna.create_study(direction='maximize')\n",
    "study_nb.optimize(objective_nb, n_trials=50)\n",
    "\n",
    "# Get the best parameters and train the model\n",
    "best_params_nb = study_nb.best_params\n",
    "print(f'Best parameters for Naive Bayes: {best_params_nb}')\n",
    "\n",
    "nb_model_tuned = GaussianNB(**best_params_nb)\n",
    "nb_model_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_nb = nb_model_tuned.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "print(f'Naive Bayes Best Accuracy: {nb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.1.0-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/124.9 MB 217.9 kB/s eta 0:09:34\n",
      "   ---------------------------------------- 0.0/124.9 MB 217.9 kB/s eta 0:09:34\n",
      "   ---------------------------------------- 0.1/124.9 MB 297.7 kB/s eta 0:07:00\n",
      "   ---------------------------------------- 0.1/124.9 MB 353.1 kB/s eta 0:05:54\n",
      "   ---------------------------------------- 0.1/124.9 MB 425.1 kB/s eta 0:04:54\n",
      "   ---------------------------------------- 0.2/124.9 MB 517.2 kB/s eta 0:04:02\n",
      "   ---------------------------------------- 0.2/124.9 MB 625.1 kB/s eta 0:03:20\n",
      "   ---------------------------------------- 0.3/124.9 MB 761.4 kB/s eta 0:02:44\n",
      "   ---------------------------------------- 0.4/124.9 MB 970.6 kB/s eta 0:02:09\n",
      "   ---------------------------------------- 0.6/124.9 MB 1.2 MB/s eta 0:01:44\n",
      "   ---------------------------------------- 0.8/124.9 MB 1.5 MB/s eta 0:01:25\n",
      "   ---------------------------------------- 1.0/124.9 MB 1.7 MB/s eta 0:01:11\n",
      "   ---------------------------------------- 1.3/124.9 MB 2.1 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 1.5/124.9 MB 2.4 MB/s eta 0:00:52\n",
      "    --------------------------------------- 1.8/124.9 MB 2.6 MB/s eta 0:00:47\n",
      "    --------------------------------------- 2.1/124.9 MB 2.9 MB/s eta 0:00:43\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.9/124.9 MB 2.6 MB/s eta 0:00:48\n",
      "    --------------------------------------- 2.9/124.9 MB 2.5 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 3.4/124.9 MB 2.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 3.5/124.9 MB 2.7 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 3.7/124.9 MB 2.8 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 4.2/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.3/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.4/124.9 MB 3.1 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.7/124.9 MB 3.1 MB/s eta 0:00:39\n",
      "   - -------------------------------------- 5.0/124.9 MB 3.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 5.2/124.9 MB 3.3 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 5.5/124.9 MB 3.4 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 5.7/124.9 MB 3.4 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 6.0/124.9 MB 3.5 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 6.3/124.9 MB 3.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 6.5/124.9 MB 3.6 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.8/124.9 MB 3.7 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 7.1/124.9 MB 3.8 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 7.4/124.9 MB 3.8 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 7.7/124.9 MB 3.9 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 8.0/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 8.2/124.9 MB 4.0 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 8.4/124.9 MB 4.0 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 8.4/124.9 MB 4.0 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 8.4/124.9 MB 4.0 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 8.7/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 9.1/124.9 MB 4.1 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 9.1/124.9 MB 4.1 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 9.3/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 9.3/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 9.3/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 9.3/124.9 MB 3.9 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 10.4/124.9 MB 4.5 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 10.8/124.9 MB 4.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 10.9/124.9 MB 4.8 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 11.1/124.9 MB 4.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 11.1/124.9 MB 4.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 11.1/124.9 MB 4.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 12.1/124.9 MB 4.8 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 12.4/124.9 MB 4.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 12.6/124.9 MB 4.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 12.9/124.9 MB 5.6 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 13.2/124.9 MB 5.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 13.5/124.9 MB 5.5 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 13.8/124.9 MB 5.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 14.1/124.9 MB 5.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 14.4/124.9 MB 5.6 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 14.7/124.9 MB 5.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 15.1/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 15.4/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 15.6/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 15.9/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 16.3/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 16.5/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 16.8/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 17.1/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 17.4/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 17.7/124.9 MB 5.8 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 18.0/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 18.2/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 18.5/124.9 MB 5.9 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 18.8/124.9 MB 6.3 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 19.1/124.9 MB 6.2 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 19.4/124.9 MB 6.4 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 19.7/124.9 MB 6.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 20.0/124.9 MB 6.7 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 20.3/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 20.6/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 20.9/124.9 MB 6.4 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 21.2/124.9 MB 6.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 21.5/124.9 MB 6.9 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 21.8/124.9 MB 6.7 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 22.1/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 22.3/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 22.6/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 22.9/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 23.2/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 23.4/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 23.8/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.0/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.3/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.5/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 24.8/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 25.1/124.9 MB 6.6 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 25.4/124.9 MB 6.6 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 25.7/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 26.0/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 26.3/124.9 MB 6.5 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 26.7/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 27.0/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 27.2/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 27.5/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 27.8/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 28.1/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 28.4/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 28.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 29.0/124.9 MB 6.6 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 29.3/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 29.6/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 29.9/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 30.2/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 30.5/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 30.8/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 31.1/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.4/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 6.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 5.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 5.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 5.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 31.7/124.9 MB 5.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 32.4/124.9 MB 5.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 32.4/124.9 MB 5.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 33.3/124.9 MB 5.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 34.1/124.9 MB 6.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 34.4/124.9 MB 6.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 34.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.1/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.4/124.9 MB 6.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 6.0 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 35.7/124.9 MB 5.9 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 36.3/124.9 MB 5.6 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 36.4/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 36.9/124.9 MB 5.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 36.9/124.9 MB 5.4 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 37.2/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 37.8/124.9 MB 5.6 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 37.8/124.9 MB 5.6 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 38.0/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 38.0/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 38.0/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 38.0/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 38.0/124.9 MB 5.3 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 38.4/124.9 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 39.5/124.9 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 39.5/124.9 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 39.5/124.9 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 39.5/124.9 MB 5.1 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 39.9/124.9 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 40.1/124.9 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 40.3/124.9 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 40.9/124.9 MB 5.0 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 41.1/124.9 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 41.4/124.9 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 41.6/124.9 MB 4.9 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 41.9/124.9 MB 4.8 MB/s eta 0:00:18\n",
      "   ------------- -------------------------- 42.1/124.9 MB 5.7 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 42.2/124.9 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 42.2/124.9 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 42.2/124.9 MB 5.6 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 42.5/124.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 42.6/124.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 43.3/124.9 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 43.5/124.9 MB 5.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 43.8/124.9 MB 5.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 43.9/124.9 MB 5.0 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 43.9/124.9 MB 5.0 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 43.9/124.9 MB 5.0 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 44.6/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 44.8/124.9 MB 4.9 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 45.0/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 45.2/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 45.4/124.9 MB 4.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 45.6/124.9 MB 4.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 45.9/124.9 MB 4.7 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 46.0/124.9 MB 5.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 46.2/124.9 MB 5.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 46.4/124.9 MB 5.0 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 46.7/124.9 MB 5.1 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 46.9/124.9 MB 5.0 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 47.1/124.9 MB 5.0 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 47.3/124.9 MB 5.0 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 47.5/124.9 MB 5.0 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 47.7/124.9 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 48.0/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 48.2/124.9 MB 4.9 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 5.5 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 48.4/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 48.4/124.9 MB 4.8 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 48.4/124.9 MB 4.5 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 48.7/124.9 MB 4.4 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 48.9/124.9 MB 4.4 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 49.1/124.9 MB 4.3 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 49.3/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 49.6/124.9 MB 4.2 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 49.8/124.9 MB 4.4 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 50.1/124.9 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 50.3/124.9 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 50.5/124.9 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 50.7/124.9 MB 4.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 51.0/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 51.2/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 51.4/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 51.7/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 51.9/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 52.1/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 52.3/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 52.6/124.9 MB 4.4 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 52.8/124.9 MB 4.3 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 53.1/124.9 MB 4.3 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 53.3/124.9 MB 4.3 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 53.5/124.9 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 53.7/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 54.0/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 54.2/124.9 MB 4.4 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 54.4/124.9 MB 4.3 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 54.7/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 54.9/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 55.1/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 55.6/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 55.8/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 56.0/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 56.2/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 56.4/124.9 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 56.5/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 56.7/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 57.0/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 57.2/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 57.4/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 57.6/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 57.9/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 58.1/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 58.3/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 58.5/124.9 MB 4.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 58.7/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 59.0/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 59.2/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 59.4/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 59.6/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 59.9/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 60.1/124.9 MB 4.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 60.3/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 60.5/124.9 MB 4.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 60.8/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 61.0/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 61.2/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 61.5/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 61.7/124.9 MB 4.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 61.9/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 62.1/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 62.4/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 62.6/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 62.8/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 63.1/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 63.3/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 63.5/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 63.8/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 64.0/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 64.2/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 64.4/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 64.6/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 64.8/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 65.1/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 65.3/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 65.6/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 65.8/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 66.0/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 66.2/124.9 MB 4.9 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 66.5/124.9 MB 4.9 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 66.7/124.9 MB 5.0 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 66.9/124.9 MB 5.0 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 67.2/124.9 MB 5.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 67.4/124.9 MB 5.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 67.7/124.9 MB 5.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 68.0/124.9 MB 5.1 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 68.2/124.9 MB 5.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 68.5/124.9 MB 5.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 68.7/124.9 MB 5.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 68.9/124.9 MB 5.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 69.2/124.9 MB 5.3 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 69.4/124.9 MB 5.3 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 69.8/124.9 MB 5.3 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.0/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.2/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.4/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.6/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.6/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.6/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.6/124.9 MB 5.4 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 70.7/124.9 MB 5.0 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 71.0/124.9 MB 5.0 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 71.9/124.9 MB 5.3 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 72.1/124.9 MB 5.4 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 72.4/124.9 MB 5.4 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 72.7/124.9 MB 5.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 72.9/124.9 MB 5.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 73.3/124.9 MB 5.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 73.5/124.9 MB 5.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 73.8/124.9 MB 5.6 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 74.1/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 74.3/124.9 MB 5.3 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 74.5/124.9 MB 5.4 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 75.4/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 75.8/124.9 MB 5.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 76.1/124.9 MB 5.8 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 76.4/124.9 MB 5.8 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 76.7/124.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 76.9/124.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 77.1/124.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 77.5/124.9 MB 5.9 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 77.8/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 78.2/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 78.4/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 78.7/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 78.9/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 79.1/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 79.5/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 79.8/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 80.0/124.9 MB 6.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 80.4/124.9 MB 6.1 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 80.6/124.9 MB 6.1 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 81.0/124.9 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 81.2/124.9 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 81.6/124.9 MB 6.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 81.8/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 82.2/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 82.5/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 82.6/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 83.0/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 83.2/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 83.6/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 83.9/124.9 MB 6.4 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 84.2/124.9 MB 6.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 84.5/124.9 MB 7.0 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 84.8/124.9 MB 7.0 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 85.1/124.9 MB 6.7 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 85.3/124.9 MB 6.6 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 85.8/124.9 MB 6.6 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 86.0/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 86.2/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 86.5/124.9 MB 6.6 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 86.8/124.9 MB 6.6 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 87.1/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 87.3/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 87.6/124.9 MB 6.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.0/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.1/124.9 MB 6.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 88.4/124.9 MB 5.8 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 89.1/124.9 MB 6.0 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 89.4/124.9 MB 5.9 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 89.5/124.9 MB 5.9 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 91.0/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 91.8/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 91.8/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.0/124.9 MB 6.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.0/124.9 MB 6.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 93.1/124.9 MB 5.8 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 94.4/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 94.4/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 94.4/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 94.4/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 95.9/124.9 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 96.0/124.9 MB 5.7 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 96.5/124.9 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 96.6/124.9 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.1/124.9 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.3/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 97.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 98.1/124.9 MB 5.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 98.2/124.9 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 98.2/124.9 MB 5.1 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 98.9/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 98.9/124.9 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 99.4/124.9 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 99.6/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 100.1/124.9 MB 6.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 100.2/124.9 MB 6.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 100.7/124.9 MB 6.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 100.8/124.9 MB 6.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 101.2/124.9 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 103.1/124.9 MB 5.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 103.1/124.9 MB 5.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 103.7/124.9 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 104.0/124.9 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 104.3/124.9 MB 5.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 104.6/124.9 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 104.9/124.9 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 105.2/124.9 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 105.5/124.9 MB 5.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 105.8/124.9 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 106.1/124.9 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 106.4/124.9 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 106.7/124.9 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 107.0/124.9 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 107.3/124.9 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 107.6/124.9 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 108.0/124.9 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.1/124.9 MB 6.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.4/124.9 MB 6.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 6.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 6.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 6.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 6.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 108.5/124.9 MB 6.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 109.1/124.9 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 109.1/124.9 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 110.1/124.9 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 5.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 5.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 111.4/124.9 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 112.6/124.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 112.9/124.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 113.2/124.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 113.5/124.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 113.8/124.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 114.2/124.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 114.5/124.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 114.8/124.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 115.1/124.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 115.4/124.9 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 115.7/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 116.0/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 116.3/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 116.6/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 116.9/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 117.2/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 117.5/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 117.8/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 118.1/124.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 118.4/124.9 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 118.7/124.9 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 119.0/124.9 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 119.4/124.9 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 119.7/124.9 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 120.0/124.9 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 120.3/124.9 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 120.6/124.9 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 120.9/124.9 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 121.2/124.9 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 121.5/124.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  121.8/124.9 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.1/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.2/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.2/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.2/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.2/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.2/124.9 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  122.3/124.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.0/124.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.0/124.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.0/124.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  123.3/124.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.0/124.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  124.9/124.9 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 124.9/124.9 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = augmented_data.drop('diagnosis_result', axis=1)\n",
    "y = augmented_data['diagnosis_result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ab_model = AdaBoostClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "ab_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_ab = ab_model.predict(X_test)\n",
    "ab_accuracy = accuracy_score(y_test, y_pred_ab)\n",
    "print(f'AdaBoost Accuracy: {ab_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes: ['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(\n",
    "    y_test)  # Use transform for consistency\n",
    "\n",
    "# Check the mapping of labels\n",
    "print(\"Encoded classes:\", label_encoder.classes_)\n",
    "# Output: Encoded classes: ['B' 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikiy\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [12:41:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test_encoded, y_pred_xgb)\n",
    "print(f'XGBoost Accuracy: {xgb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.944\n",
      "AdaBoost Accuracy: 0.848\n",
      "XGBoost Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(f'AdaBoost Accuracy: {ab_accuracy}')\n",
    "print(f'XGBoost Accuracy: {xgb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.944\n",
      "AdaBoost Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = augmented_data.drop('diagnosis_result', axis=1)\n",
    "y = augmented_data['diagnosis_result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "# AdaBoost Classifier\n",
    "ab_model = AdaBoostClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "ab_model.fit(X_train, y_train)\n",
    "y_pred_ab = ab_model.predict(X_test)\n",
    "ab_accuracy = accuracy_score(y_test, y_pred_ab)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# # xgb_model.fit(X_train, y_train)\n",
    "# y_pred_xgb = xgb_model.predict(X_test)\n",
    "# xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Summary of Boosting Techniques Accuracies\n",
    "print(f'Gradient Boosting Accuracy: {gb_accuracy}')\n",
    "print(f'AdaBoost Accuracy: {ab_accuracy}')\n",
    "# print(f'XGBoost Accuracy: {xgb_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have already split your data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize MLPClassifier\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(\n",
    "    100, 50), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "print(f'MLP Accuracy: {mlp_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have imported necessary libraries and defined your data as earlier\n",
    "\n",
    "# Initialize and optimize other models (Decision Tree, Logistic Regression, Naive Bayes, Boosting)\n",
    "# ...\n",
    "\n",
    "# Train and evaluate MLP\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(\n",
    "    100, 50), max_iter=500, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(f'MLP Accuracy: {mlp_accuracy}')\n",
    "\n",
    "# Print accuracies of other models\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
